{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search Engine\n",
    "## for the mathematics department at Brown University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Semin Kim. Last Update: 2017/01/05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a web search engine for the department of mathematics at Brown University.\n",
    "\n",
    "1. Crawler\n",
    "    * Use BeautifulSoup for HTML parsing.\n",
    "    * BFS through link information. \n",
    "    * Visit pages whose hostname ends with 'math.brown.edu'.\n",
    "    * Scrape only text pages and skip pages like pdf and image files.  \n",
    "1. Indexing\n",
    "    * Use SQLite for a database. \n",
    "    * Use an inverted index for a schema. \n",
    "1. Word Process\n",
    "    * Use NLTK.\n",
    "    * Apply the Porter stemming and remove English stopwords for words in indexing and querying.\n",
    "    * Use only alphanumeric character for simplicity. (limitation: 'info@math.brown.edu' is parsed as 'info math brown edu')\n",
    "1. Search and Ranking\n",
    "    * Retrieve pages that contain every word in a query (after stemming and removing stopwords).\n",
    "    * Use the PageRank algorithm to rank matched pages.\n",
    "    * To maintain the Markov property, transfer the probability of links toward an outside of math.brown.edu to the original page. \n",
    "1. TODO\n",
    "    * Improve the ranking algorithm by combining methods, such as word frequency, word location, and link text together with the  PageRank algorithm with appropriate weights. \n",
    "    * Use id instead of raw data for database space efficiency.\n",
    "    * Add a feedback routine such as learning from click to improve ranking. \n",
    "\n",
    "*Reference*\n",
    "* Zhai, C & Massung, S. (2016). *Text Data Management and Analysis*. ACM Books.\n",
    "* Raschka, S. (2015). *Python Machine Learning*. Packt Publishing. \n",
    "* Segaran, T. (2007). *Programming Collective Intelligence*. O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3, re, time, sys \n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup, Comment, Doctype\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All SQL queries implemented in DBController only. \n",
    "# DBController provides easy api to access DB, and also encapsulate DB schema. \n",
    "class DBController:\n",
    "    def __init__(self):\n",
    "        db_name = 'search_engine.db'\n",
    "        self.__db_name = db_name\n",
    "        self.__con = sqlite3.connect(db_name)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.__con.commit()\n",
    "        self.__con.close()\n",
    "    \n",
    "    def initDB(self):\n",
    "        table_names = ['doc_list', 'word_list', 'word_posting', 'link_list', \n",
    "                        'pagerank_list', 'error_doc_list']\n",
    "        for table in table_names:\n",
    "            cur = self.__con.cursor()\n",
    "            if cur.execute(\"select * from sqlite_master \\\n",
    "                           where name ='%s' and type='table'\" %table).fetchone():\n",
    "                self.__con.execute('drop table %s' %table)\n",
    "\n",
    "        self.__con.execute(\"create table doc_list(doc)\")\n",
    "        self.__con.execute(\"create table word_list(word, n_doc, total_freq)\")\n",
    "        self.__con.execute(\"create table word_posting(word_id, doc_id, freq, position)\")\n",
    "        self.__con.execute(\"create table link_list(from_doc_id, to_doc_id, link_text)\")\n",
    "        self.__con.execute(\"create table pagerank_list(doc_id, pagerank)\")\n",
    "        self.__con.execute(\"create table error_doc_list(doc, error_msg)\")\n",
    "    \n",
    "    def isDocIndexed(self, url):\n",
    "        cur = self.__con.cursor()\n",
    "        row = cur.execute(\"select rowid, doc from doc_list \\\n",
    "                           where doc = '%s'\" % url).fetchone()\n",
    "        if row:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def addDoc(self, url):\n",
    "        if self.isDocIndexed(url):\n",
    "            return\n",
    "        self.__con.execute(\"insert into doc_list (doc) values ('%s')\" %url)\n",
    "        \n",
    "    def addWord(self, word, url, freq, position):\n",
    "        cur = self.__con.cursor()\n",
    "        \n",
    "        rowid = None\n",
    "        n_doc = 0\n",
    "        total_freq = 0\n",
    "        \n",
    "        # add word to word_list\n",
    "        # If word exists, update counts.  \n",
    "        row = cur.execute(\"select rowid, word, n_doc, total_freq from word_list \\\n",
    "                            where word = '%s'\"% word).fetchone()\n",
    "        if row:\n",
    "            rowid = row[0]\n",
    "            n_doc = row[2]\n",
    "            total_freq = row[3]\n",
    "        else:\n",
    "            rowid = self.__con.execute(\"insert into word_list (word, n_doc, total_freq) \\\n",
    "                                        values ('%s',0,0)\" \n",
    "                                        %(word)).lastrowid\n",
    "        \n",
    "        self.__con.execute(\"update word_list set n_doc=%d, total_freq=%d \\\n",
    "                            where word='%s'\"\n",
    "                            %(n_doc+1, total_freq+freq, word))\n",
    "        \n",
    "        # add word to word_posting. \n",
    "        self.__con.execute(\"insert into word_posting (word_id, doc_id, freq, position) \\\n",
    "                            values ('%s', '%s', %d, '%s')\"\n",
    "                            %(word, url, freq, position))\n",
    "        \n",
    "    def addLink(self, from_url, to_url, link_text):\n",
    "        self.__con.execute(\"insert into link_list(from_doc_id, to_doc_id, link_text) \\\n",
    "                            values ('%s', '%s', '%s')\" \n",
    "                            %(from_url, to_url, link_text))\n",
    "  \n",
    "    def isErrorDoc(self, url):\n",
    "        cur = self.__con.cursor()\n",
    "        row = cur.execute(\"select rowid, doc from error_doc_list \\\n",
    "                           where doc = '%s'\" % url).fetchone()\n",
    "        if row:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def addErrorDoc(self, url, error_msg=''):\n",
    "        if self.isErrorDoc(url):\n",
    "            return\n",
    "        # add url to error_doc_list\n",
    "        self.__con.execute(\"insert into error_doc_list (doc, error_msg) \\\n",
    "                            values ('%s', '%s')\" %(url, error_msg))\n",
    "    \n",
    "    def getDocs(self, word):\n",
    "        # return list of documents that contain a single word.\n",
    "        cur = self.__con.cursor()\n",
    "        \n",
    "        matches = None\n",
    "        rows = cur.execute(\"select word_id, doc_id, freq, position from word_posting \\\n",
    "                            where word_id='%s'\" %word).fetchall()\n",
    "        docs = [row[1] for row in rows]\n",
    "        return docs\n",
    "    \n",
    "    def getDocsMulti(self, words):\n",
    "        # return list of documents that contain every word in words.\n",
    "        matches = set()\n",
    "        for word in words:\n",
    "            docs = set(self.getDocs(word))\n",
    "            if not matches:\n",
    "                matches = docs\n",
    "            else:\n",
    "                matches = matches.intersection(docs)\n",
    "        return list(matches)\n",
    "    \n",
    "    def getWord(self, word):\n",
    "        cur = self.__con.cursor()\n",
    "        \n",
    "        n_doc = 0\n",
    "        total_freq = 0\n",
    "        row = cur.execute(\"select word, n_doc, total_freq from word_list \\\n",
    "                           where word='%s'\" %(word)).fetchone()\n",
    "        if row:\n",
    "            n_doc = row[1]\n",
    "            total_freq = row[2]\n",
    "            \n",
    "        return n_doc, total_freq\n",
    "    \n",
    "    def getWordPosting(self, word, url):\n",
    "        cur = self.__con.cursor()\n",
    "        \n",
    "        freq = 0\n",
    "        position = []\n",
    "        row = cur.execute(\"select word_id, doc_id, freq, position from word_posting \\\n",
    "                           where word_id='%s' and doc_id='%s'\" \n",
    "                           %(word, url)).fetchone()\n",
    "        if row:\n",
    "            freq = row[2]\n",
    "            position = [int(i) for i in row[3][1:-1].split(',')]\n",
    "            \n",
    "        return freq, position\n",
    "    \n",
    "    def updatePageRank(self, n_iter=20):\n",
    "        print('update PageRank')\n",
    "        self.__con.execute(\"delete from pagerank_list\")\n",
    "        \n",
    "        cur = self.__con.cursor()\n",
    "        docs = cur.execute(\"select rowid, doc from doc_list\").fetchall()\n",
    "        doc_list = [row[1] for row in docs]\n",
    "        hash_doc_index = {doc:i for (i, doc) in enumerate(doc_list)}\n",
    "\n",
    "        n = len(docs)\n",
    "        A = np.zeros((n,n)) # Markov Matrix\n",
    "\n",
    "        for doc in doc_list:\n",
    "            doc_idx = hash_doc_index[doc]\n",
    "            links = cur.execute(\"select from_doc_id, to_doc_id from link_list \\\n",
    "                                 where from_doc_id='%s'\" %doc).fetchall()\n",
    "            n_outlink = len(links)\n",
    "\n",
    "            prob_stay = 1\n",
    "            if n_outlink > 0:\n",
    "                prob_out = 1/n_outlink\n",
    "                for row2 in links:\n",
    "                    to_doc = row2[1]\n",
    "                    if to_doc in hash_doc_index:\n",
    "                        to_doc_idx = hash_doc_index[to_doc]\n",
    "                        A[doc_idx, to_doc_idx] += prob_out\n",
    "                        prob_stay -= prob_out\n",
    "\n",
    "            A[doc_idx, doc_idx] += prob_stay \n",
    "                # make A 'Markov matrix'. \n",
    "                # transfer probability of links to outside of doc_list \n",
    "                # to the original page.  \n",
    "\n",
    "        B = np.ones((n,n)) / (n*np.ones((n,n)))\n",
    "        A = A*0.85 + B*0.15\n",
    "        \n",
    "        Ak = A\n",
    "        for i in range(n_iter-1):\n",
    "            Ak = Ak.dot(A)\n",
    "\n",
    "        pagerank_list = Ak[0] * 100\n",
    "        print('Check Markov property: %.2f (should be 100.00)' %pagerank_list.sum())\n",
    "\n",
    "        for doc, idx in hash_doc_index.items():\n",
    "            rank = pagerank_list[idx]\n",
    "            self.__con.execute(\"insert into pagerank_list (doc_id, pagerank) \\\n",
    "                                values ('%s', %.5f)\" %(doc, rank))\n",
    "            \n",
    "    def getPageRank(self, url):\n",
    "        cur = self.__con.cursor()\n",
    "        \n",
    "        pagerank = 0\n",
    "        row = cur.execute(\"select doc_id, pagerank from pagerank_list \\\n",
    "                           where doc_id='%s'\" %(url)).fetchone()\n",
    "        if row:\n",
    "            pagerank = row[1]\n",
    "            \n",
    "        return pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextUtil:\n",
    "    def getText(self, node):\n",
    "        if node.name in ['head', 'script', 'style'] \\\n",
    "            or isinstance(node, Comment) \\\n",
    "            or isinstance(node, Doctype):\n",
    "            return ''\n",
    "\n",
    "        t = node.string\n",
    "        if t:\n",
    "            return re.sub('[\\W]+', ' ', t).strip()\n",
    "        else:\n",
    "            ret = []\n",
    "            for child in node.contents:\n",
    "                t2 = self.getText(child)\n",
    "                if t2 != '':\n",
    "                    ret.append(t2)\n",
    "            return ' '.join(ret)\n",
    "   \n",
    "    def preprocess(self, word):\n",
    "        porter = PorterStemmer()\n",
    "        stop = stopwords.words('english')\n",
    "\n",
    "        word = word.lower().strip()\n",
    "        if word in stop:\n",
    "            return ''\n",
    "\n",
    "        word = porter.stem(word)\n",
    "        return word\n",
    "\n",
    "    def tokenizer(self, words):\n",
    "        ret = []\n",
    "        for word in re.split('[\\W]+', words):\n",
    "            word = self.preprocess(word)\n",
    "            if word != '':\n",
    "                ret.append(word)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, file_name):\n",
    "        self.f = open(file_name, 'w')\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.f.close()\n",
    "        \n",
    "    def log(self, s, stdout=False):\n",
    "        self.f.write(s+'\\n')\n",
    "        if stdout:\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def crawl(self, pages=[], depth=2, timeout=1):\n",
    "        # define basic BFS of page graph using link. \n",
    "        # isValidUrl defines which pages to visit.\n",
    "        \n",
    "        log = Logger('search_engine_crawl.log')\n",
    "        log.log('start crawl', stdout=1)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        t1 = time.time()\n",
    "        \n",
    "        dbcon = DBController()\n",
    "        dbcon.initDB()\n",
    "\n",
    "        for d in range(depth):\n",
    "            log.log('\\n\\n depth: %d, pages: %d' %(d, len(pages)), stdout=1)\n",
    "            \n",
    "            cnt=0\n",
    "            next_pages = []\n",
    "            for url in pages:\n",
    "                try:    \n",
    "                    if dbcon.isErrorDoc(url) \\\n",
    "                        or dbcon.isDocIndexed(url) \\\n",
    "                        or not self.isValidUrl(url):\n",
    "                        continue\n",
    "\n",
    "                    # open page. skip non-html file. \n",
    "                    res = urlopen(url, timeout=timeout)\n",
    "                    content_type = res.info()['Content-Type']\n",
    "                    if not content_type.startswith('text/html'):\n",
    "                        log.log('skip: %s. %s' %(content_type, url))\n",
    "                        dbcon.addErrorDoc(url, content_type)\n",
    "                        continue\n",
    "                    \n",
    "                    # parse html and add to index\n",
    "                    soup = BeautifulSoup(res.read(), 'html.parser')\n",
    "                    dbcon.addDoc(url)\n",
    "\n",
    "                    # log\n",
    "                    log.log('%5d sec (d=%.2f) | %5d. visiting %s' \n",
    "                             %(time.time()-t0, time.time()-t1, cnt, url))\n",
    "                    cnt+=1\n",
    "                    t1 = time.time()\n",
    "\n",
    "                    # parge page text\n",
    "                    text = TextUtil().getText(soup)\n",
    "                    \n",
    "                    # add word\n",
    "                    words = TextUtil().tokenizer(text)\n",
    "                    word_cnt = {} # {word: (freq, position)}\n",
    "                    for idx, word in enumerate(words):\n",
    "                        if word not in word_cnt:\n",
    "                            word_cnt[word] = [0, []]\n",
    "                        word_cnt[word][0] += 1\n",
    "                        word_cnt[word][1].append(idx)\n",
    "\n",
    "                    for word in word_cnt:\n",
    "                        dbcon.addWord(word, url, word_cnt[word][0], word_cnt[word][1])\n",
    "\n",
    "                    # parse links for BFS loop\n",
    "                    link_url_list = []\n",
    "                    for node in soup.find_all('a'):\n",
    "                        link_text = TextUtil().getText(node) \n",
    "                        link_text = re.sub('[\\s]+', ' ', link_text)\n",
    "                        href = node.get('href')\n",
    "                        if href and link_text:\n",
    "                            link_url = urljoin(url, href)\n",
    "                            link_url = link_url.split('#')[0]\n",
    "                            if self.isValidUrl(link_url):\n",
    "                                dbcon.addLink(url, link_url, link_text)\n",
    "                                link_url_list.append(link_url)\n",
    "\n",
    "                    next_pages += link_url_list\n",
    "                except:\n",
    "                    log.log(\"error: %s. url: %s\" %(sys.exc_info()[1], url))\n",
    "                    dbcon.addErrorDoc(url, sys.exc_info()[1])\n",
    "            \n",
    "            log.log(' visited pages: %d' %cnt, stdout=1)\n",
    "            pages = next_pages\n",
    "            \n",
    "        log.log('finish crawl', stdout=1)\n",
    "        \n",
    "    def isValidUrl(self, url):\n",
    "        if url.startswith('http'):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "        \n",
    "class BrownMathCrawler(Crawler):\n",
    "    def isValidUrl(self, url):\n",
    "        isBrownMath = False\n",
    "        up = urlparse(url)\n",
    "        if up and up.hostname and up.hostname.endswith('math.brown.edu'):\n",
    "            isBrownMath = True\n",
    "            \n",
    "        if url.startswith('http') and isBrownMath:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Ranker:\n",
    "    def rank(self, docs, words):\n",
    "        pass\n",
    "    \n",
    "class NoRanker(Ranker):\n",
    "    def rank(self, docs, words):\n",
    "        return [(doc, 0) for doc in docs]\n",
    "    \n",
    "class WordFreqRanker(Ranker):\n",
    "    def rank(self, docs, words):\n",
    "        doc_score = []\n",
    "        dbcon = DBController()\n",
    "        for doc in docs:\n",
    "            total_freq = 0\n",
    "            for word in words:\n",
    "                freq, position = dbcon.getWordPosting(word, doc)\n",
    "                total_freq += freq\n",
    "            doc_score.append((doc, total_freq))\n",
    "        doc_score = sorted(doc_score, key=lambda x: -x[1])\n",
    "        return doc_score\n",
    "\n",
    "class PageRankRanker(Ranker):\n",
    "    def __init__(self):\n",
    "        DBController().updatePageRank()\n",
    "\n",
    "    def rank(self, docs, words):\n",
    "        doc_score = []\n",
    "        dbcon = DBController()\n",
    "        for doc in docs:\n",
    "            pagerank = dbcon.getPageRank(doc)\n",
    "            doc_score.append((doc, pagerank))\n",
    "        doc_score = sorted(doc_score, key=lambda x: -x[1])\n",
    "        return doc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    def __init__(self, ranker=PageRankRanker):\n",
    "        self.ranker = ranker()\n",
    "        \n",
    "    def findMatches(self, query):\n",
    "        dbcon = DBController()\n",
    "        \n",
    "        words = TextUtil().tokenizer(query)\n",
    "        docs = dbcon.getDocsMulti(words)\n",
    "        \n",
    "        doc_score = self.ranker.rank(docs, words)\n",
    "        return doc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crawl Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start crawl\n",
      "\n",
      "\n",
      " depth: 0, pages: 3\n",
      " visited pages: 3\n",
      "\n",
      "\n",
      " depth: 1, pages: 144\n",
      " visited pages: 89\n",
      "\n",
      "\n",
      " depth: 2, pages: 1749\n",
      " visited pages: 192\n",
      "\n",
      "\n",
      " depth: 3, pages: 2038\n",
      " visited pages: 387\n",
      "\n",
      "\n",
      " depth: 4, pages: 4715\n",
      " visited pages: 390\n",
      "finish crawl\n"
     ]
    }
   ],
   "source": [
    "crawler = BrownMathCrawler()\n",
    "\n",
    "crawler.crawl(pages=['https://www.math.brown.edu', \n",
    "                     'https://www.math.brown.edu/faculty.php', \n",
    "                     'https://www.math.brown.edu/gradstuds.php'], \n",
    "              depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061\n",
      "16631\n",
      "11844\n",
      "142789\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect('search_engine.db')\n",
    "c = con.cursor()\n",
    "\n",
    "rows1 = c.execute(\"select * from doc_list\").fetchall()\n",
    "print(len(rows1))\n",
    "rows2 = c.execute(\"select * from link_list\").fetchall()\n",
    "print(len(rows2))\n",
    "rows3 = c.execute(\"select * from word_list\").fetchall()\n",
    "print(len(rows3))\n",
    "rows4 = c.execute(\"select * from word_posting\").fetchall()\n",
    "print(len(rows4))\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>http://dug.math.brown.edu/contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>http://dug.math.brown.edu/home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>http://dug.math.brown.edu/links-and-resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>http://dug.math.brown.edu/links-and-resources/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   doc\n",
       "159                         http://dug.math.brown.edu/\n",
       "164                  http://dug.math.brown.edu/contact\n",
       "394                     http://dug.math.brown.edu/home\n",
       "163      http://dug.math.brown.edu/links-and-resources\n",
       "162  http://dug.math.brown.edu/links-and-resources/..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc = pd.DataFrame(rows1, columns=['doc'])\n",
    "df_doc.sort_values(['doc'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_doc_id</th>\n",
       "      <th>to_doc_id</th>\n",
       "      <th>link_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "      <td>http://dug.math.brown.edu/math-at-brown</td>\n",
       "      <td>Math at Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "      <td>http://dug.math.brown.edu/system/app/pages/rec...</td>\n",
       "      <td>Recent Site Activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "      <td>http://dug.math.brown.edu/contact</td>\n",
       "      <td>go here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "      <td>http://dug.math.brown.edu/Introduction%20to%20...</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>http://dug.math.brown.edu/</td>\n",
       "      <td>http://dug.math.brown.edu/Whim%20on%20Tourname...</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     from_doc_id  \\\n",
       "2471  http://dug.math.brown.edu/   \n",
       "2485  http://dug.math.brown.edu/   \n",
       "2484  http://dug.math.brown.edu/   \n",
       "2483  http://dug.math.brown.edu/   \n",
       "2482  http://dug.math.brown.edu/   \n",
       "\n",
       "                                              to_doc_id             link_text  \n",
       "2471            http://dug.math.brown.edu/math-at-brown         Math at Brown  \n",
       "2485  http://dug.math.brown.edu/system/app/pages/rec...  Recent Site Activity  \n",
       "2484                  http://dug.math.brown.edu/contact               go here  \n",
       "2483  http://dug.math.brown.edu/Introduction%20to%20...                  here  \n",
       "2482  http://dug.math.brown.edu/Whim%20on%20Tourname...                  here  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_link = pd.DataFrame(rows2, columns=['from_doc_id', 'to_doc_id', 'link_text'])\n",
    "df_link.sort_values(['from_doc_id']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>n_doc</th>\n",
       "      <th>total_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>math</td>\n",
       "      <td>585</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>brown</td>\n",
       "      <td>537</td>\n",
       "      <td>1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>mathemat</td>\n",
       "      <td>533</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>482</td>\n",
       "      <td>3083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2</td>\n",
       "      <td>479</td>\n",
       "      <td>3085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  n_doc  total_freq\n",
       "171      math    585        3683\n",
       "97      brown    537        1689\n",
       "112  mathemat    533        1944\n",
       "804         1    482        3083\n",
       "855         2    479        3085"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_list = pd.DataFrame(rows3, columns=['word', 'n_doc', 'total_freq'])\n",
    "df_word_list.sort_values('n_doc', ascending=0)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>freq</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>math</td>\n",
       "      <td>http://www.math.brown.edu/%7Ecalcplacement/Cal...</td>\n",
       "      <td>154</td>\n",
       "      <td>[27, 34, 41, 46, 51, 93, 95, 100, 104, 119, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100211</th>\n",
       "      <td>math</td>\n",
       "      <td>https://www.math.brown.edu/~banchoff/CalcPlace...</td>\n",
       "      <td>154</td>\n",
       "      <td>[27, 34, 41, 46, 51, 93, 95, 100, 104, 119, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121624</th>\n",
       "      <td>mathfrak</td>\n",
       "      <td>http://www.math.brown.edu/~jhs/MA0253/MA0253Ho...</td>\n",
       "      <td>144</td>\n",
       "      <td>[6, 391, 397, 705, 709, 710, 713, 715, 718, 72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137606</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.math.brown.edu/~banchoff/midpoint/f...</td>\n",
       "      <td>136</td>\n",
       "      <td>[5, 34, 47, 90, 136, 157, 161, 184, 187, 243, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121498</th>\n",
       "      <td>k</td>\n",
       "      <td>http://www.math.brown.edu/~jhs/MA0253/MA0253Ho...</td>\n",
       "      <td>134</td>\n",
       "      <td>[307, 316, 333, 352, 359, 372, 385, 417, 423, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_id                                             doc_id  freq  \\\n",
       "33661       math  http://www.math.brown.edu/%7Ecalcplacement/Cal...   154   \n",
       "100211      math  https://www.math.brown.edu/~banchoff/CalcPlace...   154   \n",
       "121624  mathfrak  http://www.math.brown.edu/~jhs/MA0253/MA0253Ho...   144   \n",
       "137606         1  http://www.math.brown.edu/~banchoff/midpoint/f...   136   \n",
       "121498         k  http://www.math.brown.edu/~jhs/MA0253/MA0253Ho...   134   \n",
       "\n",
       "                                                 position  \n",
       "33661   [27, 34, 41, 46, 51, 93, 95, 100, 104, 119, 13...  \n",
       "100211  [27, 34, 41, 46, 51, 93, 95, 100, 104, 119, 13...  \n",
       "121624  [6, 391, 397, 705, 709, 710, 713, 715, 718, 72...  \n",
       "137606  [5, 34, 47, 90, 136, 157, 161, 184, 187, 243, ...  \n",
       "121498  [307, 316, 333, 352, 359, 372, 385, 417, 423, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_posting = pd.DataFrame(rows4, columns=['word_id', 'doc_id', 'freq', 'position'])\n",
    "df_word_posting.sort_values(['freq', 'word_id'], ascending=[0,0])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Search Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update PageRank\n",
      "Check Markov property: 100.00 (should be 100.00)\n"
     ]
    }
   ],
   "source": [
    "se = SearchEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.math.brown.edu/~jhs', 1.40686),\n",
       " ('http://www.math.brown.edu/~abrmovic/', 0.28716),\n",
       " ('https://www.math.brown.edu/contacts.html', 0.18715),\n",
       " ('http://www.math.brown.edu/~holmer/', 0.18683),\n",
       " ('http://www.math.brown.edu/~abrmovic', 0.17683)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.findMatches('address of the department')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.math.brown.edu/grad_prog.html', 0.21659),\n",
       " ('http://www.math.brown.edu/~wise/past_events.html', 0.09808),\n",
       " ('http://www.math.brown.edu/~mtassy', 0.08526),\n",
       " ('https://www.math.brown.edu/grad_prog_reqs.html', 0.07561),\n",
       " ('http://www.math.brown.edu/grad_prog.html', 0.05146)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.findMatches('admission graduate')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.math.brown.edu/%7Ecalcplacement/CalcPlacement.html', 0.40501),\n",
       " ('https://www.math.brown.edu/course_desc.html', 0.39526),\n",
       " ('https://www.math.brown.edu/ugrad_prog.html', 0.22806),\n",
       " ('http://www.math.brown.edu/~abrmovic/MA/f1617/35', 0.19673),\n",
       " ('http://www.math.brown.edu/~mtchan/2016Spring_1040.html', 0.13292)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.findMatches('calculus 2 requirements')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.math.brown.edu/course_desc.html', 0.39526),\n",
       " ('http://www.math.brown.edu/course_desc.html', 0.12977),\n",
       " ('http://www.math.brown.edu/~wongpin101/gradsem/seminarf13.html', 0.12418),\n",
       " ('https://www.math.brown.edu/phds.html', 0.12299),\n",
       " ('http://www.math.brown.edu/%7Etcanderson/Thesisfinal4.pdf', 0.11936)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.findMatches('harmonic map')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.findMatches('search results should be empty for this query')[:5]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
